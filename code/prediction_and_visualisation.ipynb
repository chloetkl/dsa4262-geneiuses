{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nbimporter\n",
    "%pip install scikit-misc\n",
    "\n",
    "import nbimporter  \n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from main import generate_predictions\n",
    "from plotnine import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Access SG-NEx data through AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # list all samples that have processed data for RNA modification detection using m6Anet\n",
    "!aws s3 ls --no-sign-request s3://sg-nex-data/data/processed_data/m6Anet/  \n",
    "\n",
    "# saves all samples that have processed data for RNA modification detection using m6Anet under data directory\n",
    "!aws s3 cp --no-sign-request s3://sg-nex-data/data/processed_data/m6Anet/ ../data/sg-nex-data/raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Prediction of SG-NEx data using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_files(raw_directory, prediction_directory):\n",
    "    \n",
    "    '''\n",
    "    Generates csv files containing prediction scores from raw SG-Nex data json files. Also appends important features to the csv files.\n",
    "    Uses generate_predictions() function from main.ipynb to write prediction to prediction_directory.\n",
    "    \n",
    "    Parameter:\n",
    "    - raw_directory: Directory that stores raw SG-Nex data json files\n",
    "    - prediction_directory: Directory to store newly generated prediction csv files.\n",
    "    '''\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(prediction_directory, exist_ok=True)\n",
    "\n",
    "    # Iterate through each folder in the data directory\n",
    "    for root, dirs, files in os.walk(raw_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                input_path = os.path.join(root, file)\n",
    "                \n",
    "                # Get the base folder name from the input path\n",
    "                folder_name = os.path.basename(root)\n",
    "                \n",
    "                # Construct the output path\n",
    "                output_path = os.path.join(prediction_directory, f\"{folder_name}.csv\")\n",
    "                \n",
    "                print(f\"Processing: {input_path}\")\n",
    "                print(f\"Output will be saved to: {output_path}\")\n",
    "                \n",
    "                # Call prediction function\n",
    "                generate_predictions(input_path, '../model/selector.joblib.gz', '../model/rf_classifier.joblib.gz', output_path, include_features = True)\n",
    "\n",
    "                # Remove the folder after the CSV is successfully exported\n",
    "                shutil.rmtree(root)\n",
    "                print(f\"Removed folder: {root}\")\n",
    "\n",
    "    # Remove sg-nex-data directory \n",
    "    sgnex_directory = os.path.dirname(raw_directory)  \n",
    "    shutil.rmtree(sgnex_directory)  # This will remove 'data/' and everything inside it\n",
    "    print(f\"Removed sg-nex-data directory: {sgnex_directory}\")\n",
    "\n",
    "raw_directory = '../data/sg-nex-data/raw'\n",
    "prediction_directory = '../output'\n",
    "generate_prediction_files(raw_directory, prediction_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Iterates through all prediction files in prediction_directory and loads csv files into their corresponding cell_line dataframe.\n",
    "All individual cell_line dataframes are concatenated to form dataframe combined_data.\n",
    "'''\n",
    "\n",
    "# Directory containing the prediction CSV files\n",
    "prediction_directory = '../output'\n",
    "\n",
    "# Dictionary to store dataframes by cell line\n",
    "cell_line_dataframes = {\n",
    "    'A549': [],\n",
    "    'Hct116': [],\n",
    "    'K562': [],\n",
    "    'HepG2': [],\n",
    "    'MCF7': []\n",
    "}\n",
    "\n",
    "# Iterate through the files in the prediction directory\n",
    "for file_name in os.listdir(prediction_directory):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(prediction_directory, file_name)\n",
    "        \n",
    "        # Load the CSV file into a dataframe\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Check the file name to determine which cell line it belongs to\n",
    "        if 'A549' in file_name:\n",
    "            df['cell_line'] = 'A549'\n",
    "            cell_line_dataframes['A549'].append(df)\n",
    "        elif 'Hct116' in file_name:\n",
    "            df['cell_line'] = 'Hct116'\n",
    "            cell_line_dataframes['Hct116'].append(df)\n",
    "        elif 'K562' in file_name:\n",
    "            df['cell_line'] = 'K562'\n",
    "            cell_line_dataframes['K562'].append(df)\n",
    "        elif 'HepG2' in file_name:\n",
    "            df['cell_line'] = 'HepG2'\n",
    "            cell_line_dataframes['HepG2'].append(df)\n",
    "        elif 'MCF7' in file_name:\n",
    "            df['cell_line'] = 'MCF7'\n",
    "            cell_line_dataframes['MCF7'].append(df)\n",
    "\n",
    "# Concatenate dataframes for each cell line into a single dataframe\n",
    "combined_data = pd.concat(\n",
    "    [pd.concat(dfs) for dfs in cell_line_dataframes.values() if dfs], \n",
    "    ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Further processing performed on dataframe for visualisations\n",
    "'''\n",
    "\n",
    "# Add additional column to categorize Modification based on score\n",
    "combined_data['Modification'] = 'Unmodified'\n",
    "combined_data.loc[combined_data['score'] > 0.9, 'Modification'] = 'Modified'\n",
    "\n",
    "# Filter the data for scores > 0.9\n",
    "filtered_data = combined_data[combined_data['score'] > 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Line graph to show Dwelling Time and Mean Current Ranges by Relative Position (-1, 0, +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate means for each category and position for dwelling time and mean current\n",
    "cell_lines = combined_data['cell_line'].unique()\n",
    "dwelling_time_means = {}\n",
    "mean_current_means = {}\n",
    "\n",
    "for cell_line in cell_lines:\n",
    "    dwelling_time_means[cell_line] = {\n",
    "        '-1_Modified': [\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '-1_dwelling_time_min'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '-1_dwelling_time_mean'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '-1_dwelling_time_max'].mean()\n",
    "        ],\n",
    "        '-1_Unmodified': [\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '-1_dwelling_time_min'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '-1_dwelling_time_mean'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '-1_dwelling_time_max'].mean()\n",
    "        ],\n",
    "        '0_Modified': [\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '0_dwelling_time_min'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '0_dwelling_time_mean'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '0_dwelling_time_max'].mean()\n",
    "        ],\n",
    "        '0_Unmodified': [\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '0_dwelling_time_min'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '0_dwelling_time_mean'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '0_dwelling_time_max'].mean()\n",
    "        ],\n",
    "        '+1_Modified': [\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '+1_dwelling_time_min'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '+1_dwelling_time_mean'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '+1_dwelling_time_max'].mean()\n",
    "        ],\n",
    "        '+1_Unmodified': [\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '+1_dwelling_time_min'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '+1_dwelling_time_mean'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '+1_dwelling_time_max'].mean()\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    mean_current_means[cell_line] = {\n",
    "        '-1_Modified': [\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '-1_mean_current_min'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '-1_mean_current_mean'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '-1_mean_current_max'].mean()\n",
    "        ],\n",
    "        '-1_Unmodified': [\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '-1_mean_current_min'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '-1_mean_current_mean'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '-1_mean_current_max'].mean()\n",
    "        ],\n",
    "        '0_Modified': [\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '0_mean_current_min'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '0_mean_current_mean'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '0_mean_current_max'].mean()\n",
    "        ],\n",
    "        '0_Unmodified': [\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '0_mean_current_min'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '0_mean_current_mean'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '0_mean_current_max'].mean()\n",
    "        ],\n",
    "        '+1_Modified': [\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '+1_mean_current_min'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '+1_mean_current_mean'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Modified') & (combined_data['cell_line'] == cell_line), '+1_mean_current_max'].mean()\n",
    "        ],\n",
    "        '+1_Unmodified': [\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '+1_mean_current_min'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '+1_mean_current_mean'].mean(),\n",
    "            combined_data.loc[(combined_data['Modification'] == 'Unmodified') & (combined_data['cell_line'] == cell_line), '+1_mean_current_max'].mean()\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Define colors for each category\n",
    "colors = {\n",
    "    '-1_Modified': 'blue',\n",
    "    '-1_Unmodified': 'lightblue',\n",
    "    '0_Modified': 'green',\n",
    "    '0_Unmodified': 'lightgreen',\n",
    "    '+1_Modified': 'orange',\n",
    "    '+1_Unmodified': 'lightcoral'\n",
    "}\n",
    "\n",
    "# Define the order of positions for plotting\n",
    "ordered_labels = ['-1_Modified', '-1_Unmodified', '0_Modified', '0_Unmodified', '+1_Modified', '+1_Unmodified']\n",
    "positions = list(range(len(ordered_labels)))  # Numeric positions for y-axis\n",
    "\n",
    "# Function to add labels above points with vertical offset\n",
    "def add_value_labels(ax, values, y_position, color):\n",
    "    for idx, val in enumerate(values):\n",
    "        # Adjust label position to prevent overlap\n",
    "        vertical_offset = 0.05 if idx == 1 else -0.2 \n",
    "        \n",
    "        ax.text( \n",
    "            val, \n",
    "            y_position + vertical_offset, \n",
    "            f'{val:.2f}', \n",
    "            va='bottom', \n",
    "            ha='center', \n",
    "            color=color, \n",
    "            fontsize=8\n",
    "        )\n",
    "\n",
    "# Dwelling time plots with FacetGrid for each cell line\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(cell_lines), figsize=(18, 6), sharey=True)\n",
    "for i, cell_line in enumerate(cell_lines):\n",
    "    ax = axes[i]\n",
    "    for label in ordered_labels:\n",
    "        color = colors[label]\n",
    "        values = dwelling_time_means[cell_line][label]\n",
    "        y_position = positions[ordered_labels.index(label)]\n",
    "        \n",
    "        # Plot line and points\n",
    "        ax.hlines(y=y_position, xmin=values[0], xmax=values[2], colors=color, label=label)\n",
    "        ax.scatter(values, [y_position] * 3, color=color)\n",
    "        \n",
    "        # Add value labels above the points\n",
    "        add_value_labels(ax, values, y_position, color)\n",
    "    \n",
    "    ax.set_yticks(positions)\n",
    "    ax.set_yticklabels(ordered_labels)\n",
    "    ax.set_title(f'{cell_line} - Dwelling Time')\n",
    "    ax.set_xlabel('Dwelling Time')\n",
    "    ax.grid(axis='x')\n",
    "\n",
    "plt.suptitle('Dwelling Time Range by Position (Modified vs Unmodified) for Each Cell Line')\n",
    "plt.tight_layout()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Mean current plots with FacetGrid for each cell line\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(cell_lines), figsize=(18, 6), sharey=True)\n",
    "for i, cell_line in enumerate(cell_lines):\n",
    "    ax = axes[i]\n",
    "    for label in ordered_labels:\n",
    "        color = colors[label]\n",
    "        values = mean_current_means[cell_line][label]\n",
    "        y_position = positions[ordered_labels.index(label)]\n",
    "        \n",
    "        # Plot line and points\n",
    "        ax.hlines(y=y_position, xmin=values[0], xmax=values[2], colors=color, label=label)\n",
    "        ax.scatter(values, [y_position] * 3, color=color)\n",
    "        \n",
    "        # Add value labels above the points\n",
    "        add_value_labels(ax, values, y_position, color)\n",
    "    \n",
    "    ax.set_yticks(positions)\n",
    "    ax.set_yticklabels(ordered_labels)\n",
    "    ax.set_title(f'{cell_line} - Mean Current')\n",
    "    ax.set_xlabel('Mean Current')\n",
    "    ax.grid(axis='x')\n",
    "\n",
    "plt.suptitle('Mean Current Range by Position (Modified vs Unmodified) for Each Cell Line')\n",
    "plt.tight_layout()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Box plot to analyse standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features to plot along with their corresponding y-limits\n",
    "features = [\n",
    "    '-1_standard_dev_mean',\n",
    "    '0_standard_dev_mean',\n",
    "    '+1_standard_dev_mean'\n",
    "]\n",
    "\n",
    "y_limits = {\n",
    "    '-1_standard_dev_mean': (0, 15),\n",
    "    '0_standard_dev_mean': (0, 15),\n",
    "    '+1_standard_dev_mean': (0, 15)\n",
    "}\n",
    "\n",
    "# Loop through each feature to create individual plots\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(\n",
    "        data=combined_data,\n",
    "        x='cell_line',\n",
    "        y=feature,\n",
    "        hue='Modification',\n",
    "        palette='Set2'\n",
    "    )\n",
    "    \n",
    "    plt.title(f'Boxplot of {feature} across all Cell Lines (Modified vs Unmodified)')\n",
    "    plt.xlabel('Cell Line')\n",
    "    plt.ylabel(feature)\n",
    "    plt.ylim(y_limits[feature])  # Set the y-limit for each feature\n",
    "    plt.legend(title='Modification', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Density Plot to analyse Distribution of Transcript Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for scores > 0.9\n",
    "filtered_data = combined_data[combined_data['score'] > 0.9]\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Loop through each cell line and plot the density\n",
    "for cell_line in filtered_data['cell_line'].unique():\n",
    "    sns.kdeplot(\n",
    "        data=filtered_data[filtered_data['cell_line'] == cell_line], \n",
    "        x='transcript_position', \n",
    "        label=cell_line, \n",
    "        fill=False, \n",
    "        bw_adjust=0.5 \n",
    "    )\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Transcript Position')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot of Transcript Positions for Each Cell Line (Score > 0.9)')\n",
    "plt.legend(title='Cell Line')\n",
    "\n",
    "# Set x-axis ticks and labels\n",
    "x_ticks = np.arange(0, filtered_data['transcript_position'].max(), 10000)\n",
    "plt.xticks(ticks=x_ticks, labels=x_ticks)\n",
    "\n",
    "# Add minor ticks at intervals of 2500\n",
    "plt.gca().set_xticks(np.arange(0, filtered_data['transcript_position'].max(), 2500), minor=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Line Graph to show Range of Modified Transcript Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the min and max transcript positions for each cell line\n",
    "range_data = filtered_data.groupby('cell_line').agg(\n",
    "    min_position=('transcript_position', 'min'),\n",
    "    max_position=('transcript_position', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Create plot\n",
    "plot = (\n",
    "    ggplot(range_data, aes(x='min_position', y='cell_line'))  # Min position on x-axis, cell line on y-axis\n",
    "    + geom_segment(aes(x='min_position', xend='max_position', y='cell_line', yend='cell_line'), size=2)\n",
    "    + geom_text(aes(x='min_position', label='min_position'), \n",
    "                nudge_x=-1, color='black', va='bottom')  # Label min values\n",
    "    + geom_text(aes(x='max_position', label='max_position'), \n",
    "                nudge_x=1, color='black', va='bottom')  # Label max values\n",
    "    + labs(\n",
    "        title='Range of Modified Transcript Positions for Each Cell Line',\n",
    "        x='Transcript Position',\n",
    "        y='Cell Line'\n",
    "    )\n",
    ")\n",
    "\n",
    "print(plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Scatterplot to analyse Score by Transcript Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot with FacetGrid\n",
    "plot = (\n",
    "    ggplot(filtered_data, aes(x='transcript_position', y='score'))\n",
    "    + geom_point(size=0.5, alpha=0.5)\n",
    "    + geom_smooth(method='loess', color='blue', span=0.3, se=True)  # Adjust span as needed\n",
    "    + labs(\n",
    "        title='Score by Transcript Position for Each Cell Line',\n",
    "        x='Transcript Position',\n",
    "        y='Score'\n",
    "    )\n",
    "    + facet_wrap('~ cell_line', ncol=2)  # Adjust ncol as needed for layout\n",
    "    + theme_bw()\n",
    "    + theme(figure_size=(12, 6))\n",
    ")\n",
    "\n",
    "print(plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### LOESS Lines overlay for all Cell Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for transcript positions < 20000\n",
    "filtered_data_overlay = filtered_data[filtered_data['transcript_position'] < 20000]\n",
    "\n",
    "# Create a combined plot for all cell lines with LOESS smooth lines (with confidence interval)\n",
    "overlay_plot_1 = (\n",
    "    ggplot(filtered_data_overlay, aes(x='transcript_position', y='score', color='cell_line', fill='cell_line', group='cell_line'))\n",
    "    + geom_smooth(method='loess', span=0.3, se=True, alpha=0.3)\n",
    "    + labs(\n",
    "        title='Overlay of LOESS Smooth Lines for All Cell Lines (Confidence Interval)',\n",
    "        x='Transcript Position',\n",
    "        y='Score'\n",
    "    )\n",
    "    + scale_x_continuous(breaks=range(0, 20001, 2500), minor_breaks=range(0, 20001, 500))  # Major ticks every 2500, minor ticks every 500\n",
    "    + theme_bw()\n",
    "    + theme(figure_size=(12, 6))\n",
    ")\n",
    "\n",
    "print(overlay_plot_1)\n",
    "\n",
    "# Create a combined plot for all cell lines with LOESS smooth lines (without confidence interval)\n",
    "overlay_plot_2 = (\n",
    "    ggplot(filtered_data_overlay, aes(x='transcript_position', y='score', color='cell_line', fill='cell_line', group='cell_line'))\n",
    "    + geom_smooth(method='loess', span=0.3, se=False, alpha=0.3)\n",
    "    + labs(\n",
    "        title='Overlay of LOESS Smooth Lines for All Cell Lines (No Confidence Interval)',\n",
    "        x='Transcript Position',\n",
    "        y='Score'\n",
    "    )\n",
    "    + scale_x_continuous(breaks=range(0, 20001, 2500), minor_breaks=range(0, 20001, 500))  # Major ticks every 2500, minor ticks every 500\n",
    "    + theme_bw()\n",
    "    + theme(figure_size=(12, 6))\n",
    ")\n",
    "\n",
    "print(overlay_plot_2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
