{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install imblearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ad192-e30f-4d21-9daf-6292a6958647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "\n",
    "# Specify the input and output file names (adjust file paths if needed)\n",
    "input_file = '../data/dataset0.json.gz'  \n",
    "output_file = '../data/dataset0.json'    \n",
    "\n",
    "# Unzip the file\n",
    "with gzip.open(input_file, 'rb') as f_in:\n",
    "    with open(output_file, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(\"File unzipped successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167d149-ce4c-4df6-9c1f-765464a14ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = []\n",
    "with open('dataset0.json', 'r') as file:\n",
    "    for line in file:\n",
    "        # Parse each line as a JSON object\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "def flatten_json(data):\n",
    "    rows = []\n",
    "\n",
    "    for entry in data:\n",
    "        for transcript_id, positions in entry.items():\n",
    "            for position, sequences in positions.items():\n",
    "                for sequence, features in sequences.items():\n",
    "                    for feature_set in features:\n",
    "                        row = {\n",
    "                            'transcript_id': transcript_id,\n",
    "                            'transcript_position': position,\n",
    "                            'sequence': sequence,\n",
    "                            '-1_dwelling_time': feature_set[0],\n",
    "                            '-1_standard_dev': feature_set[1],\n",
    "                            '-1_mean_current': feature_set[2],\n",
    "                            '0_dwelling_time': feature_set[3],\n",
    "                            '0_standard_dev': feature_set[4],\n",
    "                            '0_mean_current': feature_set[5],\n",
    "                            '+1_dwelling_time': feature_set[6],\n",
    "                            '+1_standard_dev': feature_set[7],\n",
    "                            '+1_mean_current': feature_set[8],\n",
    "                        }\n",
    "                        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "# Flatten the data\n",
    "flattened_data = flatten_json(data)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(flattened_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca1c069-c7af-419d-8e0a-b259ae1bb46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as csv\n",
    "df.to_csv('dataset0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels = pd.read_csv('../code/data.info.labelled')\n",
    "\n",
    "print(labels.info())  # To get summary information about the DataFrame\n",
    "print(labels.head())  # Preview the first few rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/dataset0.csv')\n",
    "\n",
    "print(features.info()) \n",
    "print(features.head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gene_and_label(features, labels):\n",
    "    \"\"\"\n",
    "    Adds gene_id and label to features dataframe\n",
    "    \n",
    "    Inputs:\n",
    "    - features: pd.DataFrame\n",
    "      Dataframe with selected features after feature engineering. Dataframe must contain transcript_id and transcript_position\n",
    "    - labels: pd.DataFrame\n",
    "      Dataframe with gene_id, transcript_id, transcript_position, and label.\n",
    "\n",
    "    Output:\n",
    "    - pd.DataFrame\n",
    "      Updated features dataframe with added columns: gene_id and label from labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    features.rename(columns={\n",
    "            'Transcript_ID': 'transcript_id',\n",
    "            'Position': 'transcript_position'\n",
    "        }, inplace=True)\n",
    "    features_labelled = pd.merge(features, labels, on=['transcript_id', 'transcript_position'], how='inner')\n",
    "    \n",
    "    return features_labelled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_labelled = add_gene_and_label(features, labels)\n",
    "print(features_labelled.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_labelled.to_csv('../data/features_labelled.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_gene_id(features_labelled, features_columns):\n",
    "    \"\"\"\n",
    "    Performs train test split based on gene_id. Returns X_train and X_test based on feature_columns\n",
    "    \n",
    "    Inputs:\n",
    "    - features_labelled: pd.DataFrame\n",
    "      Updated features dataframe with added columns: gene_id and label from labels.\n",
    "      \n",
    "    Output:\n",
    "    - X_train: pd.DataFrame\n",
    "    - X_test: pd.DataFrame\n",
    "    - y_train: pd.DataFrame\n",
    "    - y_test: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    df = features_labelled\n",
    "\n",
    "    # Get unique genes\n",
    "    unique_genes = df['gene_id'].unique()\n",
    "    \n",
    "    # Perform the train-test split on genes\n",
    "    genes_train, genes_test = train_test_split(unique_genes, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Split the dataset based on the gene split\n",
    "    train_data = df[df['gene_id'].isin(genes_train)]\n",
    "    test_data = df[df['gene_id'].isin(genes_test)]\n",
    "    \n",
    "    # Create the feature and target variables for training and testing\n",
    "    X_train = train_data[feature_columns]\n",
    "    y_train = train_data['label']\n",
    "    X_test = test_data[feature_columns]\n",
    "    y_test = test_data['label']\n",
    "    \n",
    "    # Output the shapes to verify the split\n",
    "    print(f\"Training Features Shape: {X_train.shape}\")\n",
    "    print(f\"Test Features Shape: {X_test.shape}\")\n",
    "    print(f\"Training Labels Shape: {y_train.shape}\")\n",
    "    print(f\"Test Labels Shape: {y_test.shape}\")\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = [\n",
    "        '-1 Dwelling Time', '-1 Standard Dev', '-1 Mean Current',\n",
    "        '0 Dwelling Time', '0 Standard Dev', '0 Mean Current',\n",
    "        '+1 Dwelling Time', '+1 Standard Dev', '+1 Mean Current'\n",
    "    ]\n",
    "X_train, X_test, y_train, y_test = train_test_split_by_gene_id(features_labelled, features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_train_data(X_train,y_train):\n",
    "    \"\"\"\n",
    "    Performs SMOTE on train data, oversampling positive class, to account for imbalanced dataset\n",
    "    \n",
    "    Inputs:\n",
    "    - features_labelled: pd.DataFrame\n",
    "      Updated features dataframe with added columns: gene_id and label from labels.\n",
    "      \n",
    "    Output:\n",
    "    - X_train: pd.DataFrame\n",
    "    - X_test: pd.DataFrame\n",
    "    - y_train: pd.DataFrame\n",
    "    - y_test: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    print(f'Label distribution before resampling:')\n",
    "    print(pd.Series(y_train).value_counts())\n",
    "    \n",
    "    smote = SMOTE(k_neighbors=5, random_state=42) \n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    print(f'Label distribution after resampling:')\n",
    "    print(pd.Series(y_train_resampled).value_counts())\n",
    "    \n",
    "    return X_train_resampled, y_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled, y_train_resampled = balance_train_data(X_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
